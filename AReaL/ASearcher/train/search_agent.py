import queue
import re
from dataclasses import dataclass, asdict
from typing import Dict, List, Tuple, Optional

@dataclass
class Record:
    """
    æœç´¢è½¨è¿¹ä¸­å•ä¸ªè®°å½•çš„æ•°æ®ç»“æ„
    
    åŒ…å«å››ç§è®°å½•ç±»å‹ï¼š
    - prompt: åˆå§‹é—®é¢˜
    - llm_gen: LLM ç”Ÿæˆçš„å†…å®¹ï¼ˆåŒ…å«å·¥å…·è°ƒç”¨ï¼‰
    - search_results: æœç´¢å¼•æ“è¿”å›çš„ç»“æœ
    - webpage: è®¿é—®ç½‘é¡µè·å–çš„å†…å®¹
    
    åŒæ—¶å­˜å‚¨ RL è®­ç»ƒæ‰€éœ€çš„ tokens å’Œ logprobs æ•°æ®
    """
    type: str # prompt/llm_gen/search_results/webpage
    text: str
    # for webpage and search results
    short_text: str = ""
    # RL data
    input_len: Optional[int] = None
    input_tokens: Optional[List[int]] = None
    output_len: Optional[int] = None
    output_tokens: Optional[List[int]] = None
    output_logprobs: Optional[List[float]] = None
    output_versions: Optional[List[int]] = None

    def to_dict(self):
        return asdict(self)

class AgentMemory:
    """
    Agent å¯¹è¯è®°å¿†ç®¡ç†å™¨
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. å­˜å‚¨å®Œæ•´çš„å¤šè½®å¯¹è¯å†å²(prompt + LLMç”Ÿæˆ + å·¥å…·ç»“æœï¼‰
    2. å°†è®°å¿†åºåˆ—è½¬æ¢ä¸ºä¸‹ä¸€è½® LLM è¾“å…¥ prompt
    3. ç»Ÿè®¡è½¨è¿¹æ‰§è¡Œæƒ…å†µ(tokensæ•°ã€å·¥å…·è°ƒç”¨æ¬¡æ•°ç­‰)
    """
    def __init__(self, prompt):
        self.memory = [Record(type="prompt", text=prompt)]
    
    def llm_gen_count(self):
        return sum([r.type == "llm_gen" for r in self.memory])
    
    def filter_records(self, record_type):
        return [r for r in self.memory if r.type == record_type]
    
    def prepare_prompt(self):
        """
        å°†è®°å¿†ä¸­çš„æ‰€æœ‰è®°å½•æ‹¼æ¥ä¸ºå®Œæ•´çš„ LLM è¾“å…¥ prompt
        
        æ‹¼æ¥é€»è¾‘ï¼š
        prompt + search_results + <think> + llm_gen + webpage + <think> + llm_gen + ...
        
        å…³é”®ç‚¹ï¼šå·¥å…·ç»“æœåä¼šæ·»åŠ  <think> æ ‡ç­¾ï¼Œå¼•å¯¼ LLM æ€è€ƒ
        Why think:
            1. è®¤çŸ¥æµç¨‹æ¨¡æ‹Ÿ: <think> æ ‡ç­¾æ¨¡æ‹Ÿäº†äººç±»æ¥æ”¶æ–°ä¿¡æ¯åçš„æ€è€ƒè¿‡ç¨‹ï¼Œå¼ºåˆ¶æ¨¡å‹åœ¨è¡ŒåŠ¨å‰è¿›è¡Œåæ€å’Œè§„åˆ’ã€‚
            2. åˆ†æ®µå¼æ¨ç†: é€šè¿‡ stop=["</think>"] å®ç°äº†"ä¿¡æ¯è¾“å…¥â†’æ€è€ƒâ†’è¡ŒåŠ¨"çš„ä¸‰é˜¶æ®µå¾ªç¯ï¼Œé¿å…äº†æ¨¡å‹åŒ†å¿™åšå‡ºå†³ç­–ã€‚
        """
        prompt = ""
        for r in self.memory:
            if r.type == "prompt":
                prompt = r.text
            elif r.type in ["search_results", "webpage"]:
                prompt = prompt + "\n\n" + r.short_text + "\n<think>\n"
            elif r.type == "llm_gen":
                prompt = prompt + r.text
            else:
                raise RuntimeError(f"Unknown record type: {r.type}")
        return prompt
    
    def add_record(self, r: Record):
        self.memory.append(r)
    
    def logging_stats(self) -> Dict:
        llm_gens = self.filter_records(record_type="llm_gen")
        search_results = self.filter_records(record_type="search_results")
        webpages = self.filter_records(record_type="webpage")
        ret = dict(
            num_llm_gens=len(llm_gens),
            num_input_tokens=sum([len(r.input_tokens) for r in llm_gens]),
            num_output_tokens=sum([len(r.output_tokens) for r in llm_gens]),
            num_search_queries=len(search_results),
            num_success_search_queries=len([r for r in search_results if "No search results are found" not in r.text]),
            num_failed_search_queries=len([r for r in search_results if "No search results are found" in r.text]),
            num_pages=len(webpages),
            num_success_url_accesses=len([r for r in webpages if ">>>> Page 1 >>>>" in r.text]),
            num_failed_url_accesses=len([r for r in webpages if ">>>> Page 1 >>>>" in r.text]),
        )
        return ret
    
    def to_dict(self):
        return [r.to_dict() for r in self.memory]

class SearchAgent:
    """
    å•ä¸ªæœç´¢ä»»åŠ¡çš„ Agent å®ä¾‹
    
    æ ¸å¿ƒèŒè´£ï¼š
    1. ç®¡ç†å•ä¸ªé—®é¢˜çš„å®Œæ•´æœç´¢è½¨è¿¹
    2. å¤„ç†å·¥å…·è°ƒç”¨ç»“æœçš„åˆ†é¡µé˜Ÿåˆ—ï¼ˆå¤§ç½‘é¡µå†…å®¹åˆ†å—å¤„ç†ï¼‰
    3. æ£€æµ‹ä»»åŠ¡å®ŒæˆçŠ¶æ€ï¼ˆæ˜¯å¦è¾“å‡ºäº† <answer> æ ‡ç­¾ï¼‰
    4. ä¸º RL è®­ç»ƒæä¾›å®Œæ•´çš„è½¨è¿¹æ•°æ®
    
    æ³¨æ„ï¼šæ¯ä¸ª SearchAgent å®ä¾‹å¯¹åº”ä¸€æ¡å®Œæ•´çš„æœç´¢è½¨è¿¹ï¼Œè®­ç»ƒå®Œæˆåä¼šè¢«é”€æ¯
    """
    def __init__(self, prompt):
        self.prompt = prompt
        self.memory = AgentMemory(prompt=prompt)
        self.summary_job_queue = queue.Queue(128)  # å·¥å…·ç»“æœåˆ†é¡µé˜Ÿåˆ—
    
    @property
    def num_turns(self):
        return self.memory.llm_gen_count()
    
    @property
    def is_finished(self):
        """
        æ£€æµ‹ Agent æ˜¯å¦å·²å®Œæˆä»»åŠ¡
        
        åˆ¤æ–­ä¾æ®ï¼šLLM ç”Ÿæˆå†…å®¹ä¸­æ˜¯å¦åŒ…å« <answer>...</answer> æ ‡ç­¾
        è¿™æ˜¯ ASearcher æ¡†æ¶ä¸­è¡¨ç¤ºä»»åŠ¡å®Œæˆçš„æ ‡å‡†æ ¼å¼
        """
        pattern = r'<answer>(.*?)</answer>'
        return any([len(re.findall(pattern, r.text, re.DOTALL)) > 0 for r in self.memory.filter_records("llm_gen")])
    
    def add_summary_jobs(self, summary_jobs):
        if not isinstance(summary_jobs, list):
            summary_jobs = [summary_jobs]
        for summary_job in summary_jobs:
            assert (summary_job.get("type", "unkown") in ["search_results", "webpage"]), ("Unknown summary_job type: " + summary_job.get("type", "unknown"))
            self.summary_job_queue.put_nowait(summary_job)
    
    def prepare_llm_query(self):
        """
        å‡†å¤‡ä¸‹ä¸€è½® LLM ç”Ÿæˆè¯·æ±‚
        
        æ ¸å¿ƒé€»è¾‘ï¼š
        1. åŸºç¡€ prompt = å†å²å¯¹è¯è®°å½•
        2. å¦‚æœæœ‰å¾…å¤„ç†çš„å·¥å…·ç»“æœ(job_queue),åˆ™æ·»åŠ åˆ° prompt æœ«å°¾, å¹¶åœ¨æœ€ååŠ å…¥<think>
           - å¼ºåˆ¶æ€§æ€è€ƒæœºåˆ¶: <think> ä¸æ˜¯å¯é€‰çš„ï¼Œè€Œæ˜¯å¿…é¡»çš„ã€‚æ¯å½“å·¥å…·ç»“æœåŠ å…¥promptæ—¶ï¼Œç³»ç»Ÿå¼ºåˆ¶è¦æ±‚æ¨¡å‹å…ˆæ€è€ƒå†è¡ŒåŠ¨ã€‚
           - Stop Token æ§åˆ¶: é€šè¿‡ stop=["</think>"] å®ç°äº†ç²¾ç¡®æ§åˆ¶ï¼Œç¡®ä¿æ¨¡å‹ä¸èƒ½è·³è¿‡æ€è€ƒé˜¶æ®µç›´æ¥è¿›å…¥ä¸‹ä¸€ä¸ªåŠ¨ä½œã€‚
           - ğŸ”„ å®Œæ•´çš„æ‰§è¡Œå¾ªç¯
                1. LLMç”Ÿæˆ: "æˆ‘éœ€è¦æœç´¢..."
                    stop tokens: ["</search>", "</access>", "</answer>"]
                2. å·¥å…·æ‰§è¡Œ: æœç´¢å¹¶è¿”å›ç»“æœ
                3. å¼ºåˆ¶æ€è€ƒé˜¶æ®µ:
                    prompt += æœç´¢ç»“æœ + "<think>\n"
                    stop tokens: ["</think>"]  # åªèƒ½åœåœ¨æ€è€ƒç»“æŸ
                4. LLMæ€è€ƒ: "ä»ç»“æœçœ‹...ä¸‹ä¸€æ­¥åº”è¯¥..."
                    å¿…é¡»è¾“å‡º </think> æ‰èƒ½åœæ­¢
                5. ç»§ç»­ç”Ÿæˆ:
                    stop tokens: ["</search>", "</access>", "</answer>"]
                    å¯ä»¥è¾“å‡ºä¸‹ä¸€ä¸ªåŠ¨ä½œ

        3. è®¾ç½®åˆé€‚çš„ stop tokens:
           - æ­£å¸¸æƒ…å†µï¼šåœåœ¨å·¥å…·è°ƒç”¨æ ‡ç­¾ </search>, </access>, </answer>
           - å¤„ç†å·¥å…·ç»“æœæ—¶ï¼šåœåœ¨ </think>ï¼ˆè®© LLM å…ˆæ€è€ƒå†ç»§ç»­ï¼‰
        
        è¿™æ˜¯ ASearcher å¼‚æ­¥æ‰§è¡Œçš„å…³é”®ï¼šå·¥å…·ç»“æœé€šè¿‡é˜Ÿåˆ—å¼‚æ­¥æ·»åŠ åˆ°å¯¹è¯ä¸­
        """
        prompt = self.memory.prepare_prompt()
        sampling_params = dict(stop=["</search>", "</access>", "</answer>"])
        if not self.summary_job_queue.empty():
            summary_job = self.summary_job_queue.get_nowait()
            if summary_job["type"] in ["search_results", "webpage"]:
                prompt = prompt + "\n\n" + summary_job["text"] + "\n<think>\n"
                new_record = Record(
                    type=summary_job["type"], 
                    text=summary_job["text"], 
                    short_text=summary_job.get("short_text", summary_job["text"]),
                )
                self.memory.add_record(new_record)
                sampling_params["stop"] = ["</think>"]
        return prompt, sampling_params
    
    def consume_llm_response(self, resp, completion_text):
        """
        å¤„ç† LLM ç”Ÿæˆç»“æœ
        
        æ ¸å¿ƒæ­¥éª¤ï¼š
        1. å°† LLM ç”Ÿæˆå†…å®¹å­˜å‚¨åˆ°è®°å¿†ä¸­ï¼ŒåŒ…å« RL è®­ç»ƒæ‰€éœ€çš„æ‰€æœ‰æ•°æ®
        2. è§£æå·¥å…·è°ƒç”¨ï¼šä»ç”Ÿæˆæ–‡æœ¬ä¸­æå– <search>, <access>, <answer> æ ‡ç­¾
        3. è¿”å›å·¥å…·è°ƒç”¨åˆ—è¡¨ä¾›å¤–éƒ¨æ‰§è¡Œ
        
        XML æ ‡ç­¾è®¾è®¡ï¼š
        - <search>æŸ¥è¯¢å†…å®¹</search>: æœç´¢å¼•æ“æŸ¥è¯¢
        - <access>URL</access>: è®¿é—®ç½‘é¡µå†…å®¹
        - <answer>æœ€ç»ˆç­”æ¡ˆ</answer>: ä»»åŠ¡å®Œæˆæ ‡å¿—
        """
        new_record = Record(
            type="llm_gen",
            text=completion_text,
            input_len=resp.input_len,
            input_tokens=resp.input_tokens,
            output_len=resp.output_len,
            output_tokens=resp.output_tokens,
            output_logprobs=resp.output_logprobs,
            output_versions=resp.output_versions            
        )
        self.memory.add_record(new_record)

        tool_calls = []
        for pattern in [r'<search>(.*?)</search>', r'<access>(.*?)</access>', r'<answer>(.*?)</answer>']:
            matches = re.findall(pattern, completion_text, re.DOTALL)
            if matches:
                match = matches[-1]
                tool_calls.append(str(pattern.replace('(.*?)', match)))

        return tool_calls

    def consume_tool_response(self, res, topk=5):
        """
        å¤„ç†å·¥å…·è°ƒç”¨ç»“æœï¼Œå®ç°å¼‚æ­¥åˆ†é¡µå¤„ç†æœºåˆ¶
        
        æœç´¢ç»“æœå¤„ç†ï¼š
        - å– top-k ä¸ªæœç´¢ç»“æœ
        - æ ¼å¼åŒ–ä¸º <information> æ ‡ç­¾åŒ…å›´çš„æ–‡æœ¬
        - æ¯ä¸ªæ–‡æ¡£é™åˆ¶åœ¨ 5000 å­—ç¬¦å†…
        
        ç½‘é¡µå†…å®¹å¤„ç†ï¼ˆå…³é”®çš„åˆ†é¡µæœºåˆ¶ï¼‰ï¼š
        - å¤§ç½‘é¡µå†…å®¹ï¼ˆæœ€å¤§ 250K å­—ç¬¦ï¼‰åˆ†å‰²ä¸ºå¤šä¸ª 25K çš„å—
        - æ¯ä¸ªå—ä½œä¸ºç‹¬ç«‹çš„ job åŠ å…¥é˜Ÿåˆ—
        - LLM ä¼šé€ä¸ªå¤„ç†è¿™äº›å—ï¼Œå®ç°æ¸è¿›å¼å†…å®¹ç†è§£
        - short_text å­˜å‚¨å‰ 100 å­—ç¬¦ç”¨äºè®°å¿†ç®¡ç†
        
        è¿™æ˜¯ ASearcher å¤„ç†è¶…é•¿ç½‘é¡µçš„æ ¸å¿ƒæœºåˆ¶
        """
        # process the search results
        if res["type"] == "search":
            summary_job = dict(type="search_results")

            documents = res["documents"][:topk]
            urls = res["urls"][:topk]

            if len(documents) > 0:
                doc_id_template = "[Doc {doc_id}]({url}):\n"
                text = "<information>\n" + "\n\n".join([doc_id_template.format(doc_id=str(k+1), url=url) + doc[:5000] for k, (doc, url) in enumerate(zip(documents, urls))]) + "\n</information>"
            else:
                text = "<information>\nNo search results are found.\n</information>"

            summary_job["text"] = text 
            self.add_summary_jobs(summary_job)
        
        # process the webpage
        elif res["type"] == "access":
            summary_jobs = []          
            page = res["page"]
            if page is not None and page.strip() != "":
                page = page[:250000]  # é™åˆ¶æœ€å¤§ç½‘é¡µé•¿åº¦
                while len(page) > 0 and len(summary_jobs) < 10:  # æœ€å¤šåˆ†å‰²ä¸º 10 ä¸ªå—
                    _len = min(25000, len(page))  # æ¯å—æœ€å¤§ 25K å­—ç¬¦
                    summary_jobs.append(dict(
                        type="webpage",
                        text=f"<information>\n>>>> Page {len(summary_jobs) + 1} >>>>\n\n" + page[:_len] + "\n</information>",
                        short_text=f"<information>\n>>>> Page {len(summary_jobs) + 1} >>>>\n\n" + page[:100] + "\n</information>",
                    ))
                    page = page[_len:]
            else:
                summary_jobs.append(dict(
                    type="webpage",
                    text="<information>\nNo More Information is Found for this URL.\n</information>",
                ))
            self.add_summary_jobs(summary_jobs)

    def get_answer(self):
        text, _ = self.prepare_llm_query()
        pattern = r'<answer>(.*?)</answer>'
        matches = re.findall(pattern, text, re.DOTALL)
        if matches:
            return matches[-1].strip()
        return None